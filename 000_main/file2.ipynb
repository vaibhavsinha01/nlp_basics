{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.S. PROPN compound\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "6 NUM compound\n",
      "million NUM pobj\n",
      "\n",
      "\n",
      "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x000001DC6F86F8F0>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x000001DC6F86D9D0>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x000001DC6E7CA7A0>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x000001DC712B3E10>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x000001DC6D89D050>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x000001DC6E7CA880>)]\n",
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
      "\n",
      "\n",
      "Tesla PROPN nsubj\n",
      "is AUX aux\n",
      "n't PART neg\n",
      "looking VERB ROOT\n",
      "into ADP prep\n",
      "startups NOUN pobj\n",
      "anymore ADV advmod\n",
      "\n",
      "\n",
      "Tesla\n",
      "PROPN\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')\n",
    "for token in doc:\n",
    "    print(token.text,token.pos_,token.dep_) # pos gives part of speech/dep stands for syntax dependencies\n",
    "\n",
    "print(\"\\n\")\n",
    "print(nlp.pipeline)\n",
    "print(nlp.pipe_names)\n",
    "print(\"\\n\")\n",
    "\n",
    "doc2 = nlp(u\"Tesla isn't looking into startups anymore\")\n",
    "for token in doc2:\n",
    "    print(token.text,token.pos_,token.dep_)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(doc2[0])\n",
    "print(doc2[0].pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Life is what happens to us while we are making other plans'\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "<class 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp(u\"Although commonly attributed to John Lennon from his song 'Beautiful Boy',\\\n",
    "           'Life is what happens to us while we are making other plans' was written by \\\n",
    "           cartoonistAllen Saunders and published in Reader\\'s Digest in 1957, when Lennon was 17.\")\n",
    "\n",
    "life_quote = doc3[16:29]\n",
    "print(life_quote)\n",
    "print(type(life_quote))\n",
    "print(type(doc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla is looking at buying U.S. startup for $6 million\n",
      "This\n",
      "True\n",
      "is\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp(\"This is the first sentence. This is another sentence. This is the last sentence.\")\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)\n",
    "\n",
    "print(doc4[6])\n",
    "\n",
    "print(doc4[6].is_sent_start)\n",
    "print(doc4[7])\n",
    "print(doc4[8].is_sent_start)\n",
    "print(doc4[9].is_sent_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"We're moving to L.A.!\"\n",
      "<spacy.vocab.Vocab object at 0x000001DC65A00160>\n",
      "794\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "mystring = '\"We\\'re moving to L.A.!\"'\n",
    "print(mystring)\n",
    "\n",
    "# doc = nlp(mystring)\n",
    "# for token in doc:\n",
    "#     print(token.text)\n",
    "\n",
    "# print(\"\\n\")\n",
    "# doc2 = nlp(u\"We're here to help! Send snail-mail, email support@oursite.com or visit us at http://www.oursite.com!\")\n",
    "# for t in doc2:\n",
    "#     print(t)\n",
    "\n",
    "# print(\"\\n\")\n",
    "# doc3 = nlp(u\"A 5km NYC cab ride costs $10.30\")\n",
    "# for t in doc3:\n",
    "#     print(t)\n",
    "\n",
    "# doc4 = nlp(u\"Let's visit St.Louis in the U.S. next year\")\n",
    "# for t in doc4:\n",
    "#     print(t)\n",
    "# print(len(doc4))\n",
    "\n",
    "print(doc4.vocab)\n",
    "print(len(doc4.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple|to|build|a|Hong|Kong|factory|for|$|6|million|"
     ]
    }
   ],
   "source": [
    "doc8 = nlp(u'Apple to build a Hong Kong factory for $6 million')\n",
    "for token in doc8:\n",
    "    print(token.text,end='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "Companies, agencies, institutions, etc.\n",
      "\n",
      "\n",
      "Hong Kong GPE\n",
      "Countries, cities, states\n",
      "\n",
      "\n",
      "$6 million MONEY\n",
      "Monetary values, including unit\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for entity in doc8.ents:\n",
    "    print(entity,entity.label_)\n",
    "    print(str(spacy.explain(entity.label_)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars\n",
      "insurance liability\n",
      "manufacturers\n"
     ]
    }
   ],
   "source": [
    "doc9 = nlp(u'Autonomous cars shift insurance liability toward manufacturers.')\n",
    "\n",
    "for chunk in doc9.noun_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"8c11e8ff6c4c47118576319423244297-0\" class=\"displacy\" width=\"1490\" height=\"377.0\" direction=\"ltr\" style=\"max-width: none; height: 377.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"170\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"170\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">going</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">build</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">U.K</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"890\">factory</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"890\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1010\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1010\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">6</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1370\">million.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1370\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8c11e8ff6c4c47118576319423244297-0-0\" stroke-width=\"2px\" d=\"M70,242.0 C70,122.0 280.0,122.0 280.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8c11e8ff6c4c47118576319423244297-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,244.0 L62,232.0 78,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8c11e8ff6c4c47118576319423244297-0-1\" stroke-width=\"2px\" d=\"M190,242.0 C190,182.0 275.0,182.0 275.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8c11e8ff6c4c47118576319423244297-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M190,244.0 L182,232.0 198,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8c11e8ff6c4c47118576319423244297-0-2\" stroke-width=\"2px\" d=\"M430,242.0 C430,182.0 515.0,182.0 515.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8c11e8ff6c4c47118576319423244297-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,244.0 L422,232.0 438,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8c11e8ff6c4c47118576319423244297-0-3\" stroke-width=\"2px\" d=\"M310,242.0 C310,122.0 520.0,122.0 520.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8c11e8ff6c4c47118576319423244297-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M520.0,244.0 L528.0,232.0 512.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8c11e8ff6c4c47118576319423244297-0-4\" stroke-width=\"2px\" d=\"M670,242.0 C670,122.0 880.0,122.0 880.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8c11e8ff6c4c47118576319423244297-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670,244.0 L662,232.0 678,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8c11e8ff6c4c47118576319423244297-0-5\" stroke-width=\"2px\" d=\"M790,242.0 C790,182.0 875.0,182.0 875.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8c11e8ff6c4c47118576319423244297-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M790,244.0 L782,232.0 798,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8c11e8ff6c4c47118576319423244297-0-6\" stroke-width=\"2px\" d=\"M550,242.0 C550,62.0 885.0,62.0 885.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8c11e8ff6c4c47118576319423244297-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M885.0,244.0 L893.0,232.0 877.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8c11e8ff6c4c47118576319423244297-0-7\" stroke-width=\"2px\" d=\"M550,242.0 C550,2.0 1010.0,2.0 1010.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8c11e8ff6c4c47118576319423244297-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1010.0,244.0 L1018.0,232.0 1002.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8c11e8ff6c4c47118576319423244297-0-8\" stroke-width=\"2px\" d=\"M1150,242.0 C1150,122.0 1360.0,122.0 1360.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8c11e8ff6c4c47118576319423244297-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1150,244.0 L1142,232.0 1158,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8c11e8ff6c4c47118576319423244297-0-9\" stroke-width=\"2px\" d=\"M1270,242.0 C1270,182.0 1355.0,182.0 1355.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8c11e8ff6c4c47118576319423244297-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270,244.0 L1262,232.0 1278,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8c11e8ff6c4c47118576319423244297-0-10\" stroke-width=\"2px\" d=\"M1030,242.0 C1030,62.0 1365.0,62.0 1365.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8c11e8ff6c4c47118576319423244297-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1365.0,244.0 L1373.0,232.0 1357.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nearly 20 thousands\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " iPods for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "doc = nlp(u\"Apple is going to build a U.K factory for $6 million.\")\n",
    "displacy.render(doc,style='dep',options={'distance':120}) # here the distance is used to adjust the size of the image\n",
    "doc = nlp(u\"Over the last quarter Apple sold nearly 20 thousands iPods for a profit of $6 million.\")\n",
    "displacy.render(doc,style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run----> run\n",
      "runner----> runner\n",
      "ran----> ran\n",
      "runs----> run\n",
      "easily----> easili\n",
      "fairly----> fairli\n",
      "fairness----> fair\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generous---->generous\n",
      "generation---->generat\n",
      "generously---->generous\n",
      "generate---->generat\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "s_stemmer = SnowballStemmer(language='english')\n",
    "words = ['run','runner','ran','runs','easily','fairly','fairness']\n",
    "\n",
    "for word in words:\n",
    "    print(word+'---->',p_stemmer.stem(word))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "words = ['generous','generation','generously','generate']\n",
    "\n",
    "print('\\n')\n",
    "for word in words:\n",
    "    print(word+'---->'+s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t PRON \t 4690420944186131903 \t I\n",
      "am \t AUX \t 10382539506755952630 \t be\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "runner \t NOUN \t 12640964157389618806 \t runner\n",
      "running \t VERB \t 12767647472892411841 \t run\n",
      "in \t ADP \t 3002984154512732771 \t in\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "race \t NOUN \t 8048469955494714898 \t race\n",
      "because \t SCONJ \t 16950148841647037698 \t because\n",
      "I \t PRON \t 4690420944186131903 \t I\n",
      "love \t VERB \t 3702023516439754181 \t love\n",
      "to \t PART \t 3791531372978436496 \t to\n",
      "run \t VERB \t 12767647472892411841 \t run\n",
      "since \t SCONJ \t 10066841407251338481 \t since\n",
      "I \t PRON \t 4690420944186131903 \t I\n",
      "ran \t VERB \t 12767647472892411841 \t run\n",
      "today \t NOUN \t 11042482332948150395 \t today\n",
      "\n",
      "\n",
      "I            PRON   4690420944186131903    I\n",
      "saw          VERB   11925638236994514241   see\n",
      "ten          NUM    7970704286052693043    ten\n",
      "mice         NOUN   1384165645700560590    mouse\n",
      "today        NOUN   11042482332948150395   today\n",
      "!            PUNCT  17494803046312582752   !\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc1 = nlp(u\"I am a runner running in a race because I love to run since I ran today\")\n",
    "\n",
    "for token in doc1:\n",
    "    print(token.text,'\\t',token.pos_,'\\t',token.lemma,'\\t',token.lemma_)\n",
    "\n",
    "def show_lemmas(text):\n",
    "    for token in text:\n",
    "        print(f\"{token.text:{12}} {token.pos_:{6}} {token.lemma:<{22}} {token.lemma_}\")\n",
    "\n",
    "print('\\n')\n",
    "doc2 = nlp(u'I saw ten mice today!')\n",
    "show_lemmas(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'they', '’ll', 'least', 'could', 'put', 'themselves', 'whose', 're', 'seem', 'becomes', 'been', 'beside', 'sometimes', 'eight', 'whenever', 'me', 'now', 'either', 'about', '’m', 'nor', 'whom', 'someone', 'everywhere', 'however', 'its', 'hereupon', 'give', 'whatever', 'ten', 'whence', 'we', 'four', 'anyone', 'was', 'part', 'using', 'alone', 'being', 'our', 'five', 'take', 'make', 'off', 'with', 'than', 'be', 'still', 'while', 'some', 'where', 'towards', 'top', 'had', 'my', \"'m\", 'thereafter', 'onto', 'another', 'ourselves', 'latter', 'afterwards', 'becoming', 'whole', 'am', 'from', 'what', 'when', 'a', 'besides', 'third', 'over', 'no', 'further', 'mostly', 'do', '’s', 'or', 'since', 'well', 'hence', 'rather', 'two', 'everything', 'call', 'such', 'six', 'moreover', 'thru', 'if', 'serious', 'please', 'twenty', 'and', 'also', 'because', 'show', 'n‘t', 'seeming', 'namely', 'who', 'those', 'by', 'sixty', 'hers', 'whereby', 'hereby', 'see', 'may', 'out', 'them', 'during', 'ours', 'meanwhile', 'elsewhere', 'through', 'thence', 'become', 'your', 'each', 'eleven', 'others', 'himself', 'therefore', 'i', 'thereby', 'hundred', '‘m', 'even', \"'s\", 'side', 'against', 'have', 'ca', 'nevertheless', 'before', 'so', 'how', 'indeed', 'go', 'regarding', 'get', '’d', 'along', 'might', 'due', 'often', 'once', 'together', 'without', 'should', '‘ve', 'anything', 'on', 'their', 'none', 'it', 'already', 'her', 'front', 'both', 'one', 'thereupon', 'back', 'him', 'herself', 'n’t', 'itself', 'really', 'fifty', 'would', 'neither', 'own', 'most', 'same', 'sometime', '’ve', 'nobody', 'latterly', 'all', 'became', 'as', 'his', \"n't\", 'quite', 'yourselves', 'will', 'unless', 'upon', 'much', 'myself', 'next', 'why', 'more', 'amount', 'under', 'hereafter', 'nothing', 'wherein', 'amongst', '‘re', 'in', 'you', 'beforehand', 'always', 'first', 'among', 'various', 'whereas', 'yet', 'above', 'us', 'former', 'were', 'btw', 'that', 'across', 'noone', 'though', 'else', 'made', 'three', 'there', '’re', 'for', 'any', 'move', 'although', 'up', 'therein', 'into', '‘s', 'less', 'say', 'otherwise', \"'ve\", 'did', 'few', 'fifteen', 'at', 'keep', 'many', 'name', 'just', 'but', 'almost', 'this', 'doing', 'these', 'anyway', 'except', 'via', 'whoever', 'twelve', '‘d', 'something', 'behind', 'every', 'then', 'nine', 'other', 'whereafter', 'after', 'must', 'seems', 'here', 'down', 'enough', 'never', 'he', 'empty', 'between', 'too', 'anywhere', 'wherever', \"'re\", 'of', 'cannot', 'mine', 'is', \"'d\", 'can', 'used', '‘ll', 'perhaps', 'within', 'she', 'whereupon', 'an', 'until', 'last', 'several', 'again', 'the', 'done', 'throughout', 'somewhere', 'to', 'yours', 'whether', 'around', 'below', 'has', 'are', \"'ll\", 'per', 'formerly', 'toward', 'nowhere', 'forty', 'seemed', 'bottom', 'everyone', 'yourself', 'which', 'very', 'does', 'thus', 'herein', 'only', 'anyhow', 'not', 'whither', 'ever', 'full', 'somehow'}\n",
      "326\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Check current stop words and count\n",
    "print(nlp.Defaults.stop_words)\n",
    "print(len(nlp.Defaults.stop_words))\n",
    "\n",
    "# Check if specific words are stop words\n",
    "print(nlp.vocab['is'].is_stop)  # 'is' is a stop word\n",
    "print(nlp.vocab['mystery'].is_stop)  # 'mystery' is not a stop word\n",
    "\n",
    "# Add a new stop word\n",
    "nlp.Defaults.stop_words.add('btw')\n",
    "nlp.vocab['btw'].is_stop = True  # Mark 'btw' as a stop word in the vocab\n",
    "print(nlp.vocab['btw'].is_stop)  # Now 'btw' is a stop word\n",
    "\n",
    "# Check if 'beyond' is a stop word\n",
    "print(nlp.vocab['beyond'].is_stop)  # 'beyond' is originally a stop word\n",
    "\n",
    "# Safely remove 'beyond' from stop words if it's there\n",
    "if 'beyond' in nlp.Defaults.stop_words:\n",
    "    nlp.Defaults.stop_words.remove('beyond')\n",
    "    nlp.vocab['beyond'].is_stop = False  # Mark 'beyond' as not a stop word\n",
    "\n",
    "# Check if 'beyond' is still a stop word\n",
    "print(nlp.vocab['beyond'].is_stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 3), (8656102463236116519, 8, 9), (8656102463236116519, 11, 14)]\n",
      "8656102463236116519 SolarPower 1 3 Solar Power\n",
      "8656102463236116519 SolarPower 8 9 solarpower\n",
      "8656102463236116519 SolarPower 11 14 Solar-power\n",
      "\n",
      "\n",
      "[(8656102463236116519, 0, 3), (8656102463236116519, 4, 5)]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# SolarPower \n",
    "# Solar-power\n",
    "# Solar power\n",
    "\n",
    "# the lower is to get the lowercase form of the token text\n",
    "# the length is used to get the length of a text,orth the exact verbatim text of a token,IS_PUNCT,IS_ASCII,IS_DIGIT,IS_UPPER,IS_STOP,IS_LOWER - are all used for the pattern purposes read more in the course\n",
    "\n",
    "pattern1 = [{'LOWER':'solarpower'}]\n",
    "pattern2 = [{'LOWER':'solar'},{'IS_PUNCT':True},{'LOWER':'power'}]\n",
    "pattern3 = [{'LOWER':'solar'},{'LOWER':'power'}]\n",
    "matcher.add('SolarPower',[pattern1,pattern2,pattern3])  # here SolarPower is the name of the matcher\n",
    "\n",
    "doc = nlp(u'The Solar Power industry continues to grow a solarpower increases. Solar-power is amazing')\n",
    "found_matches=matcher(doc)\n",
    "print(found_matches)\n",
    "\n",
    "for match_id,start,end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "    span = doc[start:end]\n",
    "    print(match_id,string_id,start,end,span.text)\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "matcher.remove('SolarPower')\n",
    "# solarpower,SolarPower\n",
    "pattern1 = [{'LOWER':'solarpower'}]\n",
    "# solar--power  / solar.power etc\n",
    "pattern2 = [{'LOWER':'solar'},{'IS_PUNCT':True,'OP':'*'},{'LOWER':'power'}]\n",
    "matcher.add('SolarPower',[pattern1,pattern2])\n",
    "\n",
    "doc2 = nlp(u'Solar--power is solarpower yay!')\n",
    "\n",
    "found_matches=matcher(doc2)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match ID: EconMatcher, Text: supply-side economics, Start: 41, End: 45\n",
      "Match ID: EconMatcher, Text: trickle-down economics, Start: 49, End: 53\n",
      "Match ID: EconMatcher, Text: voodoo economics, Start: 54, End: 56\n",
      "Match ID: EconMatcher, Text: free-market economics, Start: 61, End: 65\n",
      "Match ID: EconMatcher, Text: supply-side economics, Start: 673, End: 677\n",
      "Match ID: EconMatcher, Text: trickle-down economics, Start: 2987, End: 2991\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "with open(r\"C:\\Users\\Vaibhav\\OneDrive\\Documents\\FolderPython\\Artificial_Intelligence\\Natural_Language_Processing\\Nlp_revision\\TextFiles\\reaganomics.txt\") as f:\n",
    "    doc = nlp(f.read())\n",
    "\n",
    "phrase_list =['voodoo economics','supply-side economics','trickle-down economics','free-market economics']\n",
    "phrase_matcher = PhraseMatcher(nlp.vocab)\n",
    "phrase_patterns = [nlp(text) for text in phrase_list]\n",
    "phrase_matcher.add('EconMatcher',None,*phrase_patterns)\n",
    "found_matches = phrase_matcher(doc)\n",
    "\n",
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get the string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    # span = doc[start-2:end+2] # this gives +-2 words\n",
    "    print(f'Match ID: {string_id}, Text: {span.text}, Start: {start}, End: {end}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
